{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: WenJun Cen  \n",
    "Date: 01/24/2020  \n",
    "File: Github  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The classes are broken down into two. The first is enum class where values are identitfied as POSITIVE, \n",
    "NEGATIVE, and NEUTRAL. The second class is for ratings greater and equal to 4, it is positive. Ratings equal to 3, it is negative. \n",
    "Ratings less than 3 will be considered negative. Ratings range from 1 to 5.\"\"\"\n",
    "\n",
    "# Create Enum class with variables\n",
    "class Score:\n",
    "    POSITIVE = 'POSITIVE'\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "\n",
    "# Create Class to get receive text and sentiment rating/score    \n",
    "class Review:\n",
    "    \n",
    "    def __init__(self, text, rating):\n",
    "        self.text = text\n",
    "        self.rating = rating\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    # return positive, neutral, or negative based on rating\n",
    "    def get_sentiment(self):\n",
    "        if self.rating >= 4:\n",
    "            return Score.POSITIVE\n",
    "        elif self.rating == 3:\n",
    "            return Score.NEUTRAL\n",
    "        else:\n",
    "            return Score.NEGATIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested by my 3 years & 2 months young grandson. I picked out 2 corners for him as starting points & he went on from there with very little help from me. His almost 2 years young sister wasn't interested in trying this puzzle.The pieces are huge! I measured two of them to give you a general idea of their size...one was 7\" x 4 1/2\". A corner piece measured 5 5/8\" x 4 1/2\".  Each sturdy piece has a nice shine & is approximately 1/8\" thick.Another plus is the storage box which has a corded handle for carrying & even more importantly...the box is roomy! Meaning your child won't have to be extra careful getting the pieces back into the box. Oh my gosh, I remember the days when I'd put my kids' puzzles away & have to keep redoing it so the lid would close. Not so with this storage box, my grandson put the pieces away in no time flat & he didn't have to fiddle around getting them in just so.Nice quality puzzle...5 stars 5.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "\n",
    "filename = 'reviews_Toys_and_Games_5.json.gz'  # Sample file.\n",
    "\n",
    "reviewText = []\n",
    "with gzip.open(filename , 'rb') as gzip_file:\n",
    "    for line in gzip_file:  # Read one line.\n",
    "        line = line.rstrip()\n",
    "        if line:  # Any JSON data on it?\n",
    "            review = json.loads(line)\n",
    "            reviewText.append(Review(review['reviewText'], review['overall'])) # Appending only comments and scores\n",
    "            \n",
    "print(reviewText[123].text, reviewText[123].rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11005, 140235, 16357]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at length of the three types of sentiments\n",
    "negative = list(filter(lambda x: x.sentiment == Score.NEGATIVE, reviewText))\n",
    "positive = list(filter(lambda x: x.sentiment == Score.POSITIVE, reviewText))\n",
    "neutral = list(filter(lambda x: x.sentiment == Score.NEUTRAL, reviewText))\n",
    "list1 = [negative, positive, neutral]\n",
    "[len(listobj) for listobj in list1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that all sentiments are proportional\n",
    "import random\n",
    "positive_prop = positive[:len(negative)]\n",
    "neutral_prop = neutral[:len(negative)]\n",
    "reviews = negative + positive_prop + neutral_prop\n",
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11005, 11005, 11005]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listprop = [negative, positive_prop, neutral_prop]\n",
    "[len(listobj) for listobj in listprop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, testing = train_test_split(reviews, train_size = 0.7, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23110\n",
      "9905\n"
     ]
    }
   ],
   "source": [
    "# Look at length of both training and testing data\n",
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension to include all text and rating\n",
    "train_x = [train.text for train in training]\n",
    "train_y = [train.sentiment for train in training]\n",
    "\n",
    "test_x = [test.text for test in testing]\n",
    "test_y = [test.sentiment for test in testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"They're nothing spectacular, but the assortment of poses and colors are nice.  Most would not stay standing due to excess plastic on the feet, and the paint was pretty chipped up, but at this price I can't really complain.\",\n",
       " 3.0,\n",
       " 'NEUTRAL')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View comment of first line\n",
    "train_x[0], training[0].rating, train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform corpus into vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Adding stop words and allowing additional future stop words by using union\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=my_stop_words, lowercase=True)\n",
    "train_vector_x = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_vector_x = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They're nothing spectacular, but the assortment of poses and colors are nice.  Most would not stay standing due to excess plastic on the feet, and the paint was pretty chipped up, but at this price I can't really complain.\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(train_vector_x[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict customer review rating/score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(random_state=123)\n",
    "clf_tree.fit(train_vector_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree.predict(test_vector_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125694093891974"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree.score(test_vector_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=10, random_state=123)\n",
    "clf_rf = clf_rf.fit(train_vector_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.predict(test_vector_x[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I couldn't believe all the good reviews and top rating for this toy after actually seeing it work.  All it does is make a single note sound with each squeeze of its stomach.  What could(n't) be more exciting?!  It goes on top of an already huge mountain of stuffed animals.  And they aren't even animals so there goes the educational factor.  Don't buy it just to have it because it is one of the top toys for the year, it is not even worth the $9.99 sale price.\",\n",
       " 'NEGATIVE')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[14], test_y[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564967188288743"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.score(test_vector_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel=\"linear\", random_state=123)\n",
    "clf_svm = clf_svm.fit(train_vector_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.predict(test_vector_x[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6339222614840989"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.score(test_vector_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_nn = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf_nn.fit(train_vector_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.predict(test_vector_x[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6324078748107017"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nn.score(test_vector_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632711008735242\n",
      "0.5119965678714209\n",
      "0.5644032988980122\n",
      "0.6334646392365183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(test_y, clf_nn.predict(test_vector_x), average='weighted'))\n",
    "print(f1_score(test_y, clf_tree.predict(test_vector_x), average='weighted'))\n",
    "print(f1_score(test_y, clf_rf.predict(test_vector_x), average='weighted'))\n",
    "print(f1_score(test_y, clf_svm.predict(test_vector_x), average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2114,  978,  249],\n",
       "       [ 972, 1734,  587],\n",
       "       [ 238,  617, 2416]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, clf_nn.predict(test_vector_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.18973194002726035%\n"
     ]
    }
   ],
   "source": [
    "print(f'Total accuracy: {(2114 + 1734 + 2416)/(3*11005)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1942, 1000,  399],\n",
       "       [1058, 1500,  735],\n",
       "       [ 410,  707, 2154]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, clf_rf.predict(test_vector_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.1694987127063456%\n"
     ]
    }
   ],
   "source": [
    "print(f'Total accuracy: {(1942 + 1500 + 2154)/(3*11005)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1684, 1112,  545],\n",
       "       [ 983, 1402,  908],\n",
       "       [ 485,  795, 1991]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, clf_tree.predict(test_vector_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.15377858549144327%\n"
     ]
    }
   ],
   "source": [
    "print(f'Total accuracy: {(1684 + 1402 + 1991)/(3*11005)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2143,  954,  244],\n",
       "       [ 998, 1703,  592],\n",
       "       [ 287,  551, 2433]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, clf_svm.predict(test_vector_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.19018627896410722%\n"
     ]
    }
   ],
   "source": [
    "print(f'Total accuracy: {(2143 + 1703 + 2433)/(3*11005)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
